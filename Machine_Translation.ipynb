{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hB3RXcYyL9gQ"
   },
   "source": [
    "# Machine Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lh65nfALNlIH"
   },
   "source": [
    "### Dataset Preparation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "KF477bqbGeNu"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "fU80Ao-AGaob"
   },
   "outputs": [],
   "source": [
    "file = open(\"ita.txt\", 'r', encoding = \"utf8\")\n",
    "raw_data = []\n",
    "\n",
    "for line in file:\n",
    "    pos = line.find(\"CC-BY\")\n",
    "    line = line[:pos-1]\n",
    "    \n",
    "    # Split the data into english and Italian\n",
    "    eng, ita = line.split('\\t')\n",
    "    \n",
    "    # form tuples of the data\n",
    "    data = eng, ita\n",
    "    raw_data.append(data)\n",
    "    \n",
    "file.close()\n",
    "\n",
    "def convert(list): \n",
    "    return tuple(list) \n",
    "  \n",
    "data = convert(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "kU5L1oaHIc5R"
   },
   "outputs": [],
   "source": [
    "def unicode_to_ascii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "\n",
    "def preprocess_sentence(s):\n",
    "    s = unicode_to_ascii(s.lower())\n",
    "    s = re.sub(r'([!.?])', r' \\1', s)\n",
    "    s = re.sub(r'[^a-zA-Z.!?]+', r' ', s)\n",
    "    s = re.sub(r'\\s+', r' ', s)\n",
    "\n",
    "    s = s.strip()\n",
    "    s = '<start>' +' '+ s +' '+' <end>'\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Ca73UuX8IdAR"
   },
   "outputs": [],
   "source": [
    "# Limiting the data and Splitting into seperate lists and add tokens\n",
    "\n",
    "data = data[:30000]\n",
    "\n",
    "lang_eng = []\n",
    "lang_ita = []\n",
    "\n",
    "raw_data_en, raw_data_ita = list(zip(*data))\n",
    "raw_data_en, raw_data_ita = list(raw_data_en), list(raw_data_ita)\n",
    "\n",
    "for i, j in zip(raw_data_en, raw_data_ita):\n",
    "  preprocessed_data_en = preprocess_sentence(i)\n",
    "  preprocessed_data_ita = preprocess_sentence(j)\n",
    "  lang_eng.append(preprocessed_data_en)\n",
    "  lang_ita.append(preprocessed_data_ita)\n",
    "\n",
    "def tokenize(lang):\n",
    "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "      filters='')\n",
    "  lang_tokenizer.fit_on_texts(lang)\n",
    "\n",
    "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "\n",
    "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
    "                                                         padding='post')\n",
    "\n",
    "  return tensor, lang_tokenizer\n",
    "\n",
    "input_tensor, inp_lang = tokenize(lang_ita)\n",
    "target_tensor, targ_lang = tokenize(lang_eng)\n",
    "\n",
    "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yVfnBuJIIdC_",
    "outputId": "3e0d1cf1-fefe-4740-9fff-18422a4da1cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24000 24000 6000 6000\n",
      "Input Language; index to word mapping\n",
      "1 ----> <start>\n",
      "12 ----> la\n",
      "205 ----> prendero\n",
      "3 ----> .\n",
      "2 ----> <end>\n",
      "\n",
      "Target Language; index to word mapping\n",
      "1 ----> <start>\n",
      "4 ----> i\n",
      "20 ----> ll\n",
      "43 ----> get\n",
      "7 ----> it\n",
      "3 ----> .\n",
      "2 ----> <end>\n"
     ]
    }
   ],
   "source": [
    "# Creating training and validation sets using an 80-20 split\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
    "\n",
    "# Show length\n",
    "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))\n",
    "\n",
    "def convert(lang, tensor):\n",
    "  for t in tensor:\n",
    "    if t!=0:\n",
    "      print (\"%d ----> %s\" % (t, lang.index_word[t]))\n",
    "\n",
    "print (\"Input Language; index to word mapping\")\n",
    "convert(inp_lang, input_tensor_train[0])\n",
    "print ()\n",
    "print (\"Target Language; index to word mapping\")\n",
    "convert(targ_lang, target_tensor_train[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eEha39YYFXn4",
    "outputId": "98456fac-e1f8-4c1a-9c5e-bed0fb212f4a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((64, 11), (64, 8)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
    "\n",
    "vocab_inp_size = len(inp_lang.word_index)+1\n",
    "vocab_tar_size = len(targ_lang.word_index)+1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WB0m23oZSRxa"
   },
   "source": [
    "### Encoder Architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "KWHj4HbGIdFX"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, inp_vocab_size, embedding_size, lstm_size, input_length):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        #Initialize Embedding layer\n",
    "        #Intialize Encoder LSTM layer\n",
    "        \n",
    "        self.lstm_size = lstm_size\n",
    "        self.embedding = tf.keras.layers.Embedding(inp_vocab_size, embedding_size)\n",
    "        self.lstm = tf.keras.layers.LSTM(lstm_size, return_sequences=True, return_state=True)\n",
    "\n",
    "    def call(self, input_sequence, states):\n",
    "      \n",
    "        embed = self.embedding(input_sequence)\n",
    "        output, state_h, state_c = self.lstm(embed, initial_state=states)\n",
    "\n",
    "        return output, state_h, state_c\n",
    "    \n",
    "    def initialize_states(self,batch_size):\n",
    "    \n",
    "        return (tf.zeros([batch_size, self.lstm_size]),\n",
    "                tf.zeros([batch_size, self.lstm_size]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sjb3_4c6Sld4"
   },
   "source": [
    "### Dot Attention:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "oCaMyZWKSe_I"
   },
   "outputs": [],
   "source": [
    "class Attention(tf.keras.layers.Layer):\n",
    "    def __init__(self,scoring_function, att_units):\n",
    "        super(Attention, self).__init__()\n",
    "        \n",
    "        self.scoring_function = scoring_function\n",
    "        self.att_units = att_units\n",
    "\n",
    "        if self.scoring_function=='dot':\n",
    "            pass\n",
    "            # For general, it would be self.wa = tf.keras.layers.Dense(att_units)\n",
    "\n",
    "\n",
    "    def call(self,decoder_hidden_state,encoder_output):\n",
    "\n",
    "        if self.scoring_function == 'dot':\n",
    "            \n",
    "            new_state = tf.expand_dims(decoder_hidden_state, -1)\n",
    "            score = tf.matmul(encoder_output, new_state)\n",
    "            weights = tf.nn.softmax(score, axis=1)\n",
    "            context = weights * encoder_output\n",
    "            context_vector = tf.reduce_sum(context, axis=1)\n",
    "                                \n",
    "            return context_vector, weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FXFVBTXDS_-Y"
   },
   "source": [
    "### One Step Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "29ycCzwaS9ZZ"
   },
   "outputs": [],
   "source": [
    "class One_Step_Decoder(tf.keras.Model):\n",
    "    def __init__(self, tar_vocab_size, embedding_dim, input_length, dec_units, score_fun, att_units):\n",
    "        super(One_Step_Decoder, self).__init__()\n",
    "        # Initialize decoder embedding layer, LSTM and any other objects needed\n",
    "        self.tar_vocab_size = tar_vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.input_length = input_length\n",
    "        self.dec_units = dec_units\n",
    "        self.score_fun = score_fun\n",
    "        self.att_units = att_units\n",
    "        self.embedding = tf.keras.layers.Embedding(self.tar_vocab_size, self.embedding_dim, \n",
    "                                                   input_length=self.input_length)\n",
    "        \n",
    "        self.lstm = tf.keras.layers.LSTM(self.dec_units, return_sequences=True, \n",
    "                                         return_state=True)\n",
    "        \n",
    "        self.output_layer = tf.keras.layers.Dense(self.tar_vocab_size)\n",
    "        \n",
    "        self.attention = Attention(self.score_fun, self.att_units)\n",
    "\n",
    "    def call(self, input_to_decoder, encoder_output, state_h, state_c):\n",
    "        \n",
    "        result = self.embedding(input_to_decoder)\n",
    "        \n",
    "        context_vector, weights = self.attention(state_h, encoder_output)\n",
    "        \n",
    "        concat = tf.concat([tf.expand_dims(context_vector, 1), result], axis=-1)\n",
    "        \n",
    "        decoder_output, hidden_state, cell_state = self.lstm(concat, initial_state=[state_h, state_c])\n",
    "        \n",
    "        final_output = tf.reshape(decoder_output, (-1, decoder_output.shape[2]))\n",
    "        final_output = self.output_layer(final_output)\n",
    "        \n",
    "        return final_output, hidden_state, cell_state, weights, context_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LP7VnWvwTLpz"
   },
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "GwF7tSNlTMy_"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, out_vocab_size, embedding_dim, output_length, dec_units ,score_fun ,att_units):\n",
    "        #Intialize necessary variables and create an object from the class onestepdecoder\n",
    "        super(Decoder, self).__init__()\n",
    "        self.out_vocab_size = out_vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.output_length = output_length\n",
    "        self.dec_units = dec_units\n",
    "        self.score_fun = score_fun\n",
    "        self.att_units = att_units\n",
    "        self.onestepdecoder = One_Step_Decoder(self.out_vocab_size, self.embedding_dim, self.output_length,\n",
    "                                               self.dec_units, self.score_fun, self.att_units)\n",
    "        \n",
    "    def call(self, input_to_decoder,encoder_output,decoder_hidden_state,decoder_cell_state):\n",
    "        \n",
    "        all_outputs= tf.TensorArray(tf.float32, size=input_to_decoder.shape[1], name=\"output_arrays\")\n",
    "        \n",
    "        \n",
    "        for timestep in range(input_to_decoder.shape[1]):\n",
    "            output, decoder_hidden_state, decoder_cell_state, weights, context_vector = self.onestepdecoder(\n",
    "                                                                                    input_to_decoder[:,timestep:timestep+1], \n",
    "                                                                                    encoder_output, \n",
    "                                                                                    decoder_hidden_state,\n",
    "                                                                                    decoder_cell_state)\n",
    "            \n",
    "            all_outputs = all_outputs.write(timestep, output)\n",
    "        \n",
    "        all_outputs = tf.transpose(all_outputs.stack(), (1, 0, 2)) \n",
    "\n",
    "        return all_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8OAoXiaITo07"
   },
   "source": [
    "### Call The Encoder Decoder Architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Qkg5csDhTW8Z"
   },
   "outputs": [],
   "source": [
    "class encoder_decoder(tf.keras.Model):\n",
    "    def __init__(self, inp_vocab_size, out_vocab_size, embedding_size, lstm_size, \n",
    "                 input_length, output_length, dec_units ,score_fun ,att_units, batch_size):\n",
    "        \n",
    "        super(encoder_decoder, self).__init__()\n",
    "        \n",
    "        self.encoder = Encoder(inp_vocab_size, embedding_size, lstm_size, input_length)\n",
    "        self.decoder = Decoder(out_vocab_size, embedding_size, output_length, \n",
    "                               dec_units, score_fun, att_units)\n",
    "    \n",
    "    def call(self, data):\n",
    "        \n",
    "        input_sequence, input_to_decoder = data[0],data[1]\n",
    "        initial_state = self.encoder.initialize_states(batch_size=64)\n",
    "        encoder_output, state_h, state_c = self.encoder(input_sequence, initial_state)\n",
    "        decoder_hidden_state = state_h\n",
    "        decoder_cell_state = state_c\n",
    "        decoder_output = self.decoder(input_to_decoder, encoder_output, decoder_hidden_state, decoder_cell_state)\n",
    "        \n",
    "        return decoder_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4r8gqMeaT4DY"
   },
   "source": [
    "### Custom Loss Function: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "A_uEicf9T2O6"
   },
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss_object(real, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "\n",
    "  return tf.reduce_mean(loss_)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C2bqE3wVUtOZ"
   },
   "source": [
    "### Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DB5pZyEFUwjl",
    "outputId": "1e3ffb1a-4c17-4834-eb75-de568d5b005c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘logs’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir logs\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"dot.h5\", monitor='val_loss', verbose=1, save_weights_only=True)\n",
    "\n",
    "logdir='logs'\n",
    "tensorboard_Visualization = TensorBoard(log_dir=logdir)\n",
    "\n",
    "input_vocab_size = len(inp_lang.word_index)+1\n",
    "output_vocab_size = len(targ_lang.word_index)+1\n",
    "\n",
    "input_len = max_length_inp\n",
    "output_len = max_length_targ\n",
    "\n",
    "lstm_size = 128\n",
    "att_units = 256\n",
    "dec_units = 128\n",
    "embedding_size = 300\n",
    "embedding_dim = 300\n",
    "score_fun = 'dot'\n",
    "steps = len(input_tensor)//64\n",
    "batch_size=64\n",
    "\n",
    "model = encoder_decoder(input_vocab_size,output_vocab_size,embedding_size,lstm_size,input_len,output_len,dec_units,score_fun,att_units, batch_size)\n",
    "\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=model.layers[0],\n",
    "                                 decoder=model.layers[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "HySImJjAU8dh"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "  loss = 0\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "    enc_output, enc_hidden,enc_state = model.layers[0](inp, enc_hidden)\n",
    "\n",
    "\n",
    "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
    "\n",
    "    for t in range(1, targ.shape[1]):\n",
    "      predictions = model.layers[1](dec_input,enc_output,enc_hidden,enc_state)\n",
    "\n",
    "      loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "\n",
    "  batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "  variables = model.layers[0].trainable_variables + model.layers[1].trainable_variables\n",
    "\n",
    "  gradients = tape.gradient(loss, variables)\n",
    "\n",
    "  optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "  return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NEYjgVJ-U_b4",
    "outputId": "575349d5-7583-4791-d471-a1f25ff55ab4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 5.3874\n",
      "Epoch 1 Batch 100 Loss 2.9330\n",
      "Epoch 1 Batch 200 Loss 2.6037\n",
      "Epoch 1 Batch 300 Loss 2.2659\n",
      "Epoch 1 Loss 2.7553\n",
      "Time taken for 1 epoch 53.019567012786865 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 2.1202\n",
      "Epoch 2 Batch 100 Loss 2.1898\n",
      "Epoch 2 Batch 200 Loss 2.0353\n",
      "Epoch 2 Batch 300 Loss 1.9416\n",
      "Epoch 2 Loss 2.0571\n",
      "Time taken for 1 epoch 13.150313138961792 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 2.0332\n",
      "Epoch 3 Batch 100 Loss 1.8416\n",
      "Epoch 3 Batch 200 Loss 1.8447\n",
      "Epoch 3 Batch 300 Loss 1.8553\n",
      "Epoch 3 Loss 1.9214\n",
      "Time taken for 1 epoch 12.573858261108398 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 1.8936\n",
      "Epoch 4 Batch 100 Loss 1.8065\n",
      "Epoch 4 Batch 200 Loss 1.7550\n",
      "Epoch 4 Batch 300 Loss 1.6071\n",
      "Epoch 4 Loss 1.7758\n",
      "Time taken for 1 epoch 13.087860345840454 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 1.6039\n",
      "Epoch 5 Batch 100 Loss 1.4878\n",
      "Epoch 5 Batch 200 Loss 1.4325\n",
      "Epoch 5 Batch 300 Loss 1.4448\n",
      "Epoch 5 Loss 1.5140\n",
      "Time taken for 1 epoch 12.99687147140503 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 1.3176\n",
      "Epoch 6 Batch 100 Loss 1.3927\n",
      "Epoch 6 Batch 200 Loss 1.3127\n",
      "Epoch 6 Batch 300 Loss 1.1755\n",
      "Epoch 6 Loss 1.2989\n",
      "Time taken for 1 epoch 12.999508142471313 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 1.1222\n",
      "Epoch 7 Batch 100 Loss 1.1017\n",
      "Epoch 7 Batch 200 Loss 1.1840\n",
      "Epoch 7 Batch 300 Loss 1.1309\n",
      "Epoch 7 Loss 1.1342\n",
      "Time taken for 1 epoch 12.825852155685425 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 1.0013\n",
      "Epoch 8 Batch 100 Loss 1.0142\n",
      "Epoch 8 Batch 200 Loss 0.9634\n",
      "Epoch 8 Batch 300 Loss 0.9171\n",
      "Epoch 8 Loss 0.9912\n",
      "Time taken for 1 epoch 12.810152292251587 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 0.9016\n",
      "Epoch 9 Batch 100 Loss 0.8437\n",
      "Epoch 9 Batch 200 Loss 0.8969\n",
      "Epoch 9 Batch 300 Loss 0.8660\n",
      "Epoch 9 Loss 0.8687\n",
      "Time taken for 1 epoch 12.969218015670776 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.7093\n",
      "Epoch 10 Batch 100 Loss 0.8236\n",
      "Epoch 10 Batch 200 Loss 0.7428\n",
      "Epoch 10 Batch 300 Loss 0.7629\n",
      "Epoch 10 Loss 0.7585\n",
      "Time taken for 1 epoch 12.966861009597778 sec\n",
      "\n",
      "Epoch 11 Batch 0 Loss 0.7206\n",
      "Epoch 11 Batch 100 Loss 0.6365\n",
      "Epoch 11 Batch 200 Loss 0.7042\n",
      "Epoch 11 Batch 300 Loss 0.6570\n",
      "Epoch 11 Loss 0.6581\n",
      "Time taken for 1 epoch 13.31101107597351 sec\n",
      "\n",
      "Epoch 12 Batch 0 Loss 0.5758\n",
      "Epoch 12 Batch 100 Loss 0.6530\n",
      "Epoch 12 Batch 200 Loss 0.5826\n",
      "Epoch 12 Batch 300 Loss 0.5867\n",
      "Epoch 12 Loss 0.5657\n",
      "Time taken for 1 epoch 13.086528062820435 sec\n",
      "\n",
      "Epoch 13 Batch 0 Loss 0.4586\n",
      "Epoch 13 Batch 100 Loss 0.4832\n",
      "Epoch 13 Batch 200 Loss 0.4851\n",
      "Epoch 13 Batch 300 Loss 0.5071\n",
      "Epoch 13 Loss 0.4817\n",
      "Time taken for 1 epoch 13.205495834350586 sec\n",
      "\n",
      "Epoch 14 Batch 0 Loss 0.4173\n",
      "Epoch 14 Batch 100 Loss 0.4163\n",
      "Epoch 14 Batch 200 Loss 0.3542\n",
      "Epoch 14 Batch 300 Loss 0.4050\n",
      "Epoch 14 Loss 0.4061\n",
      "Time taken for 1 epoch 13.137596607208252 sec\n",
      "\n",
      "Epoch 15 Batch 0 Loss 0.3409\n",
      "Epoch 15 Batch 100 Loss 0.3785\n",
      "Epoch 15 Batch 200 Loss 0.3373\n",
      "Epoch 15 Batch 300 Loss 0.3719\n",
      "Epoch 15 Loss 0.3399\n",
      "Time taken for 1 epoch 13.028141736984253 sec\n",
      "\n",
      "Epoch 16 Batch 0 Loss 0.2953\n",
      "Epoch 16 Batch 100 Loss 0.2295\n",
      "Epoch 16 Batch 200 Loss 0.3094\n",
      "Epoch 16 Batch 300 Loss 0.3074\n",
      "Epoch 16 Loss 0.2843\n",
      "Time taken for 1 epoch 12.833295583724976 sec\n",
      "\n",
      "Epoch 17 Batch 0 Loss 0.2969\n",
      "Epoch 17 Batch 100 Loss 0.2334\n",
      "Epoch 17 Batch 200 Loss 0.2581\n",
      "Epoch 17 Batch 300 Loss 0.2918\n",
      "Epoch 17 Loss 0.2375\n",
      "Time taken for 1 epoch 12.667210102081299 sec\n",
      "\n",
      "Epoch 18 Batch 0 Loss 0.2368\n",
      "Epoch 18 Batch 100 Loss 0.2204\n",
      "Epoch 18 Batch 200 Loss 0.1832\n",
      "Epoch 18 Batch 300 Loss 0.1774\n",
      "Epoch 18 Loss 0.1988\n",
      "Time taken for 1 epoch 12.785019397735596 sec\n",
      "\n",
      "Epoch 19 Batch 0 Loss 0.1525\n",
      "Epoch 19 Batch 100 Loss 0.1972\n",
      "Epoch 19 Batch 200 Loss 0.1409\n",
      "Epoch 19 Batch 300 Loss 0.1615\n",
      "Epoch 19 Loss 0.1663\n",
      "Time taken for 1 epoch 12.698532104492188 sec\n",
      "\n",
      "Epoch 20 Batch 0 Loss 0.1523\n",
      "Epoch 20 Batch 100 Loss 0.1319\n",
      "Epoch 20 Batch 200 Loss 0.1958\n",
      "Epoch 20 Batch 300 Loss 0.1000\n",
      "Epoch 20 Loss 0.1410\n",
      "Time taken for 1 epoch 12.844841480255127 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "\n",
    "  enc_hidden = model.layers[0].initialize_states(64)\n",
    "  total_loss = 0\n",
    "\n",
    "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "    batch_loss = train_step(inp, targ, enc_hidden)\n",
    "    total_loss += batch_loss\n",
    "\n",
    "    if batch % 100 == 0:\n",
    "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                   batch,\n",
    "                                                   batch_loss.numpy()))\n",
    "      \n",
    "  if (epoch + 1) % 2 == 0:\n",
    "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "\n",
    "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))\n",
    "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v9ZczUDcVG9B"
   },
   "source": [
    "### Translate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Excafr5LU_9p"
   },
   "outputs": [],
   "source": [
    "def predict(input_sentence):\n",
    "\n",
    "  attention_plot = np.zeros((output_len, input_len))\n",
    "\n",
    "  input_sentence = preprocess_sentence(input_sentence)\n",
    "\n",
    "  inputs = [inp_lang.word_index[i] for i in input_sentence.split()]\n",
    "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                         maxlen=input_len,\n",
    "                                                         padding='post')\n",
    "  inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "  result = ''\n",
    "  \n",
    "  encoder_output,state_h,state_c = model.layers[0](inputs,[tf.zeros((1, lstm_size)),tf.zeros((1, lstm_size))])\n",
    "\n",
    "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
    "\n",
    "  for t in range(output_len):\n",
    "   predictions,state_h,state_c,attention_weights,context_vector = model.layers[1].onestepdecoder(dec_input,\n",
    "                                                                                                 encoder_output,\n",
    "                                                                                                 state_h,\n",
    "                                                                                                 state_c)\n",
    "\n",
    "   attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "   attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "   predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "   result += targ_lang.index_word[predicted_id] + ' '\n",
    "\n",
    "   if targ_lang.index_word[predicted_id] == '<end>':\n",
    "     return result, input_sentence, attention_plot\n",
    "\n",
    "   dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "  return result, input_sentence, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "O-U2_Lb-VObw"
   },
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "  result, sent, attention_plot = predict(sentence)\n",
    "\n",
    "  print('Input: %s' % (sent))\n",
    "  print('Predicted translation: {}'.format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K3sl-j0yVQax",
    "outputId": "b720ce20-9143-40c6-b171-12e80a490341"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> ciao !  <end>\n",
      "Predicted translation: hello ! <end> \n"
     ]
    }
   ],
   "source": [
    "translate(u'ciao!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rcgnOVlEYiez"
   },
   "source": [
    "## Conclusion:\n",
    "### We have successfully constructed our machine translation model with the help of Sequence To Sequence Modeling and dot attention mechanism to achieve an overall low loss and higher accuracy of predictions."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Machine Translation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
